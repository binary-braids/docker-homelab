name: monitoring

networks:
  proxy:
    external: true

volumes:
  prometheus-data:
    name: prometheus-data
  alertmanager-data:
    name: alertmanager-data
  grafana-data:
    name: grafana-data

services:

  prometheus:
    image: prom/prometheus:latest@sha256:49214755b6153f90a597adcbff0252cc61069f8ab69ce8411285cd4a560e8038
    container_name: prometheus
    restart: unless-stopped
    networks:
      - proxy
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - prometheus-data:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-remote-write-receiver'
      - '--web.external-url=https://prometheus.binarybraids.com'
    configs:
    - source: prometheus.yml
      target: /etc/prometheus/prometheus.yml
    - source: rules.yml
      target: /etc/prometheus/rules.yml
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.binarybraids.com`)"
      - "traefik.http.routers.prometheus.entrypoints=websec"
      - "traefik.http.routers.prometheus.tls=true"
      - "traefik.http.routers.prometheus.service=prometheus"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
      - "traefik.docker.network=proxy"

  alertmanager:
    image: prom/alertmanager:latest@sha256:27c475db5fb156cab31d5c18a4251ac7ed567746a2483ff264516437a39b15ba
    container_name: alertmanager
    restart: unless-stopped
    networks:
      - proxy
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - alertmanager-data:/etc/alertmanager
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--web.external-url=https://prometheus.binarybraids.com'
    configs:
    - source: alertmanager.yml
      target: /etc/alertmanager/alertmanager.yml
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.alertmanager.rule=Host(`alertmanager.binarybraids.com`)"
      - "traefik.http.routers.alertmanager.entrypoints=https"
      - "traefik.http.routers.alertmanager.tls=true"
      - "traefik.http.routers.alertmanager.service=alertmanager"
      - "traefik.http.services.alertmanager.loadbalancer.server.port=9093"
      - "traefik.docker.network=proxy"

  grafana:
    image: grafana/grafana:latest@sha256:62d2b9d20a19714ebfe48d1bb405086081bc602aa053e28cf6d73c7537640dfb
    container_name: grafana
    restart: unless-stopped
    networks:
      - proxy
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - grafana-data:/var/lib/grafana
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.binarybraids.com`)"
      - "traefik.http.routers.grafana.entrypoints=https"
      - "traefik.http.routers.grafana.tls=true"
      - "traefik.http.routers.grafana.service=grafana"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"
      - "traefik.docker.network=proxy"

  pve-exporter:
    image: prompve/prometheus-pve-exporter:latest@sha256:79a5598906697b1a5a006d09f0200528a77c6ff1568faf018539ac65824454df
    container_name: pve-exporter
    restart: unless-stopped
    networks:
      - proxy
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - /docker/pve-exporter:/etc/prometheus/  
    configs:
    - source: pve.yml
      target: /etc/prometheus/pve.yml
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.pve-exporter.rule=Host(`pve-exporter.binarybraids.com`)"
      - "traefik.http.routers.pve-exporter.entrypoints=https"
      - "traefik.http.routers.pve-exporter.tls=true"
      - "traefik.http.routers.pve-exporter.service=pve-exporter"
      - "traefik.http.services.pve-exporter.loadbalancer.server.port=9221"
      - "traefik.docker.network=proxy"      

configs:
  prometheus.yml:
    content: |
      global:
        scrape_interval: 5m

      rule_files:
        - "rules.yml"

      alerting:
        alertmanagers:
        - static_configs:
          - targets:
            - alertmanager.binarybraids.com

      scrape_configs:
        - job_name: 'prometheus'
          static_configs:
            - targets: ['prometheus.binarybraids.com']

        - job_name: 'pve'
          static_configs:
          - targets:
            - prod-host-01.binarybraids.com
            - prod-host-02.binarybraids.com 
          metrics_path: /pve
          params:
            module: [default]
          relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: pve-exporter.binarybraids.com

        - job_name: 'windows'
          static_configs:
          - targets:
            - vm-prod-dc-01.ad.binarybraids.com:9182
            - vm-prod-dc-02.ad.binarybraids.com:9182
            - vm-prod-bkp-01.ad.binarybraids.com:9182
          relabel_configs:
          - source_labels: [__address__]
            target_label: instance
            regex: "([^:]+).*"
            replacement: '$${1}'

        - job_name: 'linux'
          static_configs:
          - targets:
            - vm-prod-kube-01.ad.binarybraids.com:9100
            - vm-prod-kube-02.ad.binarybraids.com:9100
            - vm-prod-kube-03.ad.binarybraids.com:9100
            - vm-prod-dkr-01.ad.binarybraids.com:9100
            - vm-prod-fs-01.ad.binarybraids.com:9100
            - vm-br-prod-fra1-001.khatharsys.net.za:9100
          relabel_configs:
          - source_labels: [__address__]
            target_label: instance
            regex: "([^:]+).*"
            replacement: '$${1}'

        - job_name: 'kube-state-metrics'
          static_configs:
          - targets:
            - kube-state-metrics.binarybraids.com

  rules.yml:
    content: |
      groups:
      - name: instance_down
        rules:
        - alert: InstanceDown
          expr: up == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Instance {{ $$labels.instance }} down"
            description: "{{ $labels.instance }} of job {{ $$labels.job }} has been down for more than 5 minutes."

      - name: prometheus
        rules:
        - alert: PrometheusJobMissing
          expr: absent(up{job="prometheus"})
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: Prometheus job missing (instance {{ $$labels.instance }})
            description: "A Prometheus job has disappeared\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
        - alert: PrometheusTargetMissing
          expr: up == 0
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Prometheus target missing (instance {{ $$labels.instance }})
            description: "A Prometheus target has disappeared. An exporter might be crashed.\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
        - alert: PrometheusAllTargetsMissing
          expr: sum by (job) (up) == 0
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Prometheus all targets missing (instance {{ $$labels.instance }})
            description: "A Prometheus job does not have living target anymore.\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
                  
      - name: windows
        rules:
        - alert: WindowsServerCpuUsage
          expr: 100 - (avg by (instance) (rate(windows_cpu_time_total{mode="idle"}[2m])) * 100) > 95
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: "Windows Server CPU Usage (instance {{ $$labels.instance }})"
            description: "CPU Usage is more than 95%\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
        - alert: WindowsServerMemoryUsage
          expr: 100 - ((windows_os_physical_memory_free_bytes / windows_cs_physical_memory_bytes) * 100) > 95
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: "Windows Server memory Usage (instance {{ $$labels.instance }})"
            description: "Memory usage is more than 95%\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
        - alert: WindowsServerDiskSpaceUsage
          expr: 100.0 - 100 * ((windows_logical_disk_free_bytes / 1024 / 1024 ) / (windows_logical_disk_size_bytes / 1024 / 1024)) > 95
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Windows Server disk Space Usage (instance {{ $$labels.instance }})"
            description: "Disk usage is more than 95%\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"

      - name: linux
        rules:
        - alert: HostHighCpuLoad
          expr: (sum by (instance) (avg by (mode, instance) (rate(node_cpu_seconds_total{mode!="idle"}[2m]))) > 0.95) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: Host high CPU load (instance {{ $$labels.instance }})
            description: "CPU load is > 95%\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
        - alert: HostOutOfMemory
          expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 5) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Host out of memory (instance {{ $$labels.instance }})
            description: "Node memory is filling up (< 5% left)\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"
        - alert: HostOutOfDiskSpace
          expr: ((node_filesystem_avail_bytes{fstype!="cifs"} * 100) / node_filesystem_size_bytes{fstype!="cifs"} < 5 and node_filesystem_readonly{fstype!="cifs"} == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Host out of disk space (instance {{ $$labels.instance }})
            description: "Disk is almost full (< 5% left)\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"

      - name: kubernetes
        rules:
        - alert: KubernetesNodeNotReady
          expr: kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 10m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Node not ready (instance {{ $$labels.instance }})
            description: "Node {{ $$labels.node }} has been unready for a long time\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"  

        - alert: KubernetesNodeOutOfPodCapacity
          expr: sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(uid, instance) group_left(node) (0 * kube_pod_info{pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{resource="pods"}) * 100 > 90
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Node out of pod capacity (instance {{ $$labels.instance }})
            description: "Node {{ $$labels.node }} is out of pod capacity\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"

        - alert: KubernetesContainerOomKiller
          expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Container oom killer (instance {{ $$labels.instance }})
            description: "Container {{ $$labels.container }} in pod {{ $$labels.namespace }}/{{ $$labels.pod }} has been OOMKilled {{ $$value }} times in the last 10 minutes.\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"

        - alert: KubernetesPodNotHealthy
          expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"}) > 0
          for: 15m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Pod not healthy (instance {{ $$labels.instance }})
            description: "Pod {{ $$labels.namespace }}/{{ $$labels.pod }} has been in a non-running state for longer than 15 minutes.\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"

        - alert: KubernetesPodCrashLooping
          expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes pod crash looping (instance {{ $$labels.instance }})
            description: "Pod {{ $$labels.namespace }}/{{ $$labels.pod }} is crash looping\n  VALUE = {{ $$value }}\n  LABELS = {{ $$labels }}"

  alertmanager.yml:
    content: |
        global:
          resolve_timeout: 5m
        route:
          receiver: "discord"
          group_by: ['alertname', 'job']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 12h

        receivers:
        - name: "discord"
          discord_configs:
          - webhook_url: ${ALERTMANAGER_WEBHOOK_URI}

  pve.yml:
    content: |
      default:
          user: monitor@pve
          password: "${PROXMOX_EXPORTER_PASSWORD}"



